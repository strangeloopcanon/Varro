### NEWRUN training review (2025-08-02 → 2025-08-11)

- **System**
  - **Model**: Qwen/Qwen3-0.6B (MLX)
  - **Training**: GSPO, response-only loss, 1 epoch/day
  - **Evaluator**: fixed strict 1–8 ranks (dedupe, clamp, pad=7)

- **Data integrity**
  - **Ranks**: valid 1–8 across days after fix
  - **Rewards**: bounded [0,1], avg ≈ 0.50, negatives = 0
  - **Training JSONs** present per day (n):
    - 20250804: 256, 20250805: 224, 20250806: 216, 20250807: 280, 20250808: 248, 20250810: 144

- **Training dynamics (epoch summaries)**
  - 2025-08-04: steps=1480, avg_reward=0.0135, avg_KL=4.52, improvement=+0.0021
  - 2025-08-05: steps=1704, avg_reward=0.0183, avg_KL=5.99, improvement=+0.0145
  - 2025-08-06: steps=1920, avg_reward=0.0219, avg_KL=7.05, improvement=+0.0238
  - 2025-08-07: steps=2200, avg_reward=0.0254, avg_KL=8.16, improvement=+0.0358
  - 2025-08-08: steps=2448, avg_reward=0.0279, avg_KL=8.88, improvement=+0.0441
  - 2025-08-10: steps=2592, avg_reward=0.0292, avg_KL=9.01, improvement=+0.0417

- **Evaluation integrity**
  - 20250810 evaluations were produced and used to build training JSON (n=144; reward mapping clean)
  - Rankings are varied; not strictly sequential

- **Generation quality (today)**
  - 20250811 predictions: 248 rollouts; avg structure score ≈ 0.826

- **Conclusions**
  - Post-fix pipeline is healthy: clean evals, stable training with steady reward and KL trends, improved structure adherence.
  - Latest model updated daily; dated checkpoints saved alongside `final_model`.

- **Next steps**
  - Add side-by-side A/B evaluation (baseline vs latest) on a fixed headline set.
  - Track per-day validation metrics (evaluator agreement, retry counts) into `training/stats/` for the paper.


